<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>NBL 625 Lecture 1 – Mathematical Foundations of Imaging</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- MathJax for equations -->
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <style>
    /* Tufte CSS - Based on Edward Tufte's design principles */

    :root {
      --bg: #fffff8;
      --text: #111;
      --text-muted: #555;
      --accent: #a00000;
      --border: #ccc;
      --margin-bg: #fefef6;
      --code-bg: #f5f5f0;
    }

    * {
      box-sizing: border-box;
    }

    html {
      font-size: 15px;
      scroll-behavior: smooth;
    }

    body {
      width: 87.5%;
      margin: 0 auto;
      padding: 5rem 0;
      max-width: 1400px;
      background-color: var(--bg);
      color: var(--text);
      font-family: et-book, Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;
      line-height: 1.6;
      counter-reset: sidenote-counter;
    }

    /* Typography */
    h1, h2, h3 {
      font-weight: 400;
      line-height: 1.2;
      margin-top: 1.4rem;
      margin-bottom: 0.5rem;
    }

    h1 {
      font-size: 3.2rem;
      margin-top: 0;
      margin-bottom: 1.5rem;
      font-weight: 400;
      line-height: 1;
    }

    h2 {
      font-style: italic;
      font-size: 2.2rem;
      margin-top: 2.1rem;
    }

    h3 {
      font-size: 1.7rem;
      font-style: italic;
    }

    p, ol, ul {
      font-size: 1.4rem;
      line-height: 2rem;
    }

    p {
      margin-top: 1.4rem;
      margin-bottom: 1.4rem;
      text-align: justify;
      padding-right: 0;
      vertical-align: baseline;
    }

    /* Newthought - Small caps at start of sections */
    .newthought {
      font-variant: small-caps;
      font-size: 1.2em;
      letter-spacing: 0.05em;
    }

    /* Subtitle */
    .subtitle {
      font-style: italic;
      font-size: 1.8rem;
      margin-top: 1rem;
      margin-bottom: 1rem;
      display: block;
      line-height: 1.4;
    }

    /* Metadata */
    .meta {
      font-size: 1.2rem;
      color: var(--text-muted);
      margin-top: 0.5rem;
      margin-bottom: 2rem;
    }

    /* Article Container */
    article {
      position: relative;
      padding: 5rem 0;
    }

    /* Main Content Column */
    section {
      width: 55%;
      padding-right: 0;
      margin-bottom: 4rem;
    }

    /* Sidenotes and margin notes */
    .sidenote,
    .marginnote {
      float: right;
      clear: right;
      margin-right: -60%;
      width: 50%;
      margin-top: 0.3rem;
      margin-bottom: 0;
      font-size: 1.1rem;
      line-height: 1.3;
      vertical-align: baseline;
      position: relative;
    }

    .sidenote-number {
      counter-increment: sidenote-counter;
    }

    .sidenote-number:after,
    .sidenote:before {
      position: relative;
      vertical-align: baseline;
    }

    .sidenote-number:after {
      content: counter(sidenote-counter);
      font-size: 1rem;
      top: -0.5rem;
      left: 0.1rem;
    }

    .sidenote:before {
      content: counter(sidenote-counter) " ";
      position: absolute;
      left: -1rem;
      font-size: 1rem;
      top: -0.5rem;
    }

    /* Margin note without number */
    .marginnote {
      margin-top: 1rem;
    }

    /* Links */
    a {
      color: inherit;
      text-decoration: none;
      border-bottom: 1px solid #777;
    }

    a:hover {
      border-bottom: 1px solid #000;
    }

    /* Figures */
    figure {
      max-width: 55%;
      margin: 2rem 0;
    }

    figure.fullwidth {
      max-width: 90%;
    }

    figure img {
      max-width: 100%;
      height: auto;
    }

    figcaption {
      margin-top: 0.5rem;
      font-size: 1.1rem;
      line-height: 1.6;
      color: var(--text-muted);
    }

    /* Epigraph */
    .epigraph {
      margin: 3em 0;
    }

    .epigraph p {
      font-style: italic;
      font-size: 1.4rem;
    }

    /* Code */
    code {
      font-family: "Consolas", "Menlo", "Monaco", monospace;
      font-size: 1.1rem;
      background-color: var(--code-bg);
      padding: 0.1rem 0.3rem;
      border-radius: 2px;
    }

    pre {
      font-family: "Consolas", "Menlo", "Monaco", monospace;
      font-size: 0.95rem;
      background-color: var(--code-bg);
      padding: 1rem;
      overflow-x: auto;
      margin: 1.4rem 0;
      line-height: 1.4;
      border-left: 3px solid var(--border);
    }

    /* Lists */
    ul, ol {
      width: 90%;
      padding-left: 2rem;
    }

    li {
      margin-bottom: 0.5rem;
    }

    /* Tables */
    table {
      margin: 1.4rem 0;
      width: auto;
      border-collapse: collapse;
      font-size: 1.2rem;
    }

    th, td {
      padding: 0.5rem 1rem;
      text-align: left;
      border-bottom: 1px solid var(--border);
    }

    th {
      font-weight: 400;
      border-bottom: 2px solid var(--text);
    }

    /* Comparison table for pixels vs voxels */
    .comparison {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 2rem;
      margin: 2rem 0;
      width: 90%;
    }

    .comparison-column h3 {
      font-size: 1.2rem;
      font-variant: small-caps;
      font-style: normal;
      margin-bottom: 0.5rem;
      letter-spacing: 0.1em;
    }

    .comparison-column ul {
      font-size: 1.2rem;
      padding-left: 1.5rem;
      width: 100%;
    }

    /* Math */
    .inline-math {
      font-family: "Computer Modern", "STIX Two Math", serif;
    }

    /* Badges */
    .badge {
      font-size: 0.9rem;
      padding: 0.2rem 0.5rem;
      border: 1px solid var(--border);
      border-radius: 3px;
      margin-right: 0.3rem;
      display: inline-block;
      color: var(--text-muted);
    }

    /* Mobile responsive */
    @media (max-width: 760px) {
      body {
        width: 90%;
        padding: 2rem 0;
      }

      section {
        width: 100%;
      }

      figure {
        max-width: 100%;
      }

      .sidenote,
      .marginnote {
        display: block;
        float: none;
        width: 100%;
        margin-right: 0;
        margin-left: 0;
        margin-top: 1rem;
        margin-bottom: 1rem;
        padding: 1rem;
        background-color: var(--margin-bg);
        border-left: 3px solid var(--border);
      }

      .comparison {
        grid-template-columns: 1fr;
        width: 100%;
      }

      h1 {
        font-size: 2.5rem;
      }

      h2 {
        font-size: 1.8rem;
      }
    }
  </style>
</head>
<body>
  <article>
    <h1>Lecture 1<br/>Mathematical Foundations of Imaging</h1>
    <p class="subtitle">Pixels, Voxels, Linear Algebra, and Fourier Transforms for Human Neuroimaging</p>
    <p class="meta">
      <strong>Course:</strong> NBL 625/425 – Methods in Human Neuroimaging<br/>
      <strong>Instructor:</strong> Mark Bolding, PhD (UAB)<br/>
      <strong>Student:</strong> Sathvik Bodepudi
    </p>

    <!-- How to Use -->
    <section id="how-to-use">
      <h2>How to Use This Chapter</h2>
      <p><span class="newthought">Read this page</span> top-to-bottom once, then revisit specific sections as needed. The flow is designed so that each new idea builds naturally on the last:</p>
      <ol>
        <li>Skim the big-picture map to see how pixels, voxels, tensors, and Fourier transforms fit together.</li>
        <li>Work through each section, pausing at margin notes labeled as limitations or critical perspectives.</li>
        <li>Engage with the images and demos—they are not decorative; they carry core intuition.</li>
        <li>Use the self-check at the end to confirm you can explain each major concept in your own words.</li>
      </ol>
      <p class="marginnote"><strong>Primary source:</strong> Core content is adapted from Mark Bolding, <em>NBL 625/425 – Methods in Human Neuroimaging, Lecture 1: Background material on mathematical foundations of imaging</em>, University of Alabama at Birmingham.</p>
    </section>

    <!-- Concept Map -->
    <section id="concept-map">
      <h2>Big Picture: From Brain to Numbers</h2>
      <p><span class="newthought">Human neuroimaging</span> converts continuous physical properties of the brain into discrete digital numbers. Three mathematical pillars underpin this translation:</p>
      <ul>
        <li><strong>Discrete spatial representation</strong> — pixels (2D) and voxels (3D).</li>
        <li><strong>Linear algebra</strong> — scalars, vectors, matrices, and tensors.</li>
        <li><strong>Frequency analysis</strong> — Fourier transforms linking time/space and frequency.</li>
      </ul>
      <p>MRI, fMRI, diffusion imaging, and PET all rely on these tools to reconstruct images, quantify changes across time, and model complex experimental designs.</p>

      <figure class="fullwidth">
        <img src="conceptual_pipeline.png" alt="Conceptual neuroimaging pipeline from brain anatomy to digital datasets" />
        <figcaption><strong>Figure 1.</strong> Conceptual pipeline illustrating the transformation from continuous brain anatomy to discrete digital representations used in neuroimaging. From physical signal acquisition, data are discretized into pixels and voxels, organized into vectors, matrices, and tensors, and transformed using Fourier-based methods for reconstruction and analysis. <em>Adapted from Bolding, NBL 625 Lecture 1.</em></figcaption>
      </figure>

      <p class="marginnote"><strong>Why these foundations matter:</strong> These choices are not neutral: how we discretize space, represent data, and transform signals governs which neural effects are visible, which artifacts appear, and how we interpret "activation" or structural differences.</p>
    </section>

    <!-- Pixels & Voxels -->
    <section id="pixels-voxels">
      <h2>Pixels and Voxels</h2>

      <h3>Pixels: 2D building blocks</h3>
      <p><span class="newthought">A pixel</span> (picture element) is the smallest unit of a 2D digital image. Each pixel stores information such as intensity or color at one location on a grid.</p>
      <ul>
        <li>Higher pixel counts → finer 2D spatial resolution.</li>
        <li>Each pixel approximates signal within a small area of a slice.</li>
        <li>Medical images often treat pixel values as physically meaningful intensities.</li>
      </ul>

      <h3>Voxels: 3D building blocks</h3>
      <p><span class="newthought">A voxel</span> (volume element) is the 3D analogue of a pixel—a tiny cube of tissue represented in a volumetric image.</p>
      <ul>
        <li>Voxel size (e.g., 1×1×1 mm) determines 3D spatial resolution.</li>
        <li>Each voxel represents an average over a non-zero volume of brain tissue.</li>
        <li>Whole-brain MRI volumes can contain hundreds of thousands of voxels.</li>
      </ul>

      <figure>
        <img src="pixels_voxels_person.png" alt="Pixel character vs voxel character" />
        <figcaption><strong>Figure 2.</strong> Cartoon example of a 2D pixel character (left) versus a 3D voxel figure (right). This mirrors the transition from 2D slices to volumetric brain reconstructions.</figcaption>
      </figure>

      <figure>
        <img src="pixels_voxels_heatmap.png" alt="Pixels vs voxels heatmap grids" />
        <figcaption><strong>Figure 3.</strong> Illustration of pixels (left) as a 2D grid of picture elements, and voxels (right) as stacked 3D volume elements.</figcaption>
      </figure>

      <div class="comparison">
        <div class="comparison-column">
          <h3>Pixels</h3>
          <ul>
            <li>2D picture elements arranged on a grid.</li>
            <li>Tiny squares describing a small area in a slice.</li>
            <li>Resolution is measured in pixels per unit distance.</li>
            <li>Used in CT, X-ray, and MRI slice images.</li>
          </ul>
        </div>
        <div class="comparison-column">
          <h3>Voxels</h3>
          <ul>
            <li>3D volume elements arranged in a volumetric grid.</li>
            <li>Tiny cubes describing a chunk of tissue.</li>
            <li>Resolution is measured in voxel dimensions (e.g., 1 mm³).</li>
            <li>Used in MRI, fMRI, PET, and diffusion imaging.</li>
          </ul>
        </div>
      </div>

      <p class="marginnote"><strong>Limitation – Resolution is a tradeoff:</strong> Smaller voxels yield better spatial resolution but lower signal-to-noise ratio and often longer scan times. In fMRI, balancing voxel size, coverage, and temporal resolution is crucial; interpretations of "no activation" must consider whether the voxel size and SNR were sufficient to detect the effect at all.</p>
    </section>

    <!-- Linear algebra -->
    <section id="linear-algebra">
      <h2>Scalars, Vectors, Matrices, and Tensors</h2>

      <h3>From single numbers to structured datasets</h3>
      <p><span class="newthought">Linear algebra</span> offers a language for organizing imaging data:</p>
      <ul>
        <li><strong>Scalar</strong>: one number (e.g., a voxel's intensity at one time).</li>
        <li><strong>Vector</strong>: ordered list of numbers (e.g., time series of one voxel).</li>
        <li><strong>Matrix</strong>: 2D grid of numbers (e.g., voxel × time or voxel × subject).</li>
        <li><strong>Tensor</strong>: higher-order array (e.g., voxel × time × condition × subject).</li>
      </ul>

      <h3>Exam score analogy</h3>
      <ul>
        <li>Scalar: one exam score.</li>
        <li>Vector: a student's scores across exams.</li>
        <li>Matrix: scores for multiple students across exams.</li>
        <li>Tensor: scores across exams, students, and semesters.</li>
      </ul>
      <p>This analogy maps directly onto neuroimaging datasets tracking many voxels across time, conditions, and participants.</p>

      <figure>
        <img src="svmt_infographic.png" alt="Scalar, vector, matrix, tensor infographic" />
        <figcaption><strong>Figure 5.</strong> Custom infographic illustrating how scalars, vectors, matrices, and tensors relate.</figcaption>
      </figure>

      <h3>Matrix–vector multiplication in imaging</h3>
      <p>A matrix can represent a linear transformation. In neuroimaging, matrices map between different representations: design matrices relate predictors to observed signals, and reconstruction operators map k-space samples to image voxels.</p>

      <figure>
        <img src="matrix_vector_eq.png" alt="Matrix times vector equals vector A x = b" />
        <figcaption><strong>Figure 6.</strong> Matrix–vector product <em>A x = b</em>. Each entry of <em>b</em> is a weighted sum of the <em>x</em> entries. Similar linear systems appear in MRI reconstruction and GLM estimation.</figcaption>
      </figure>

      <h3>Eigenvectors, determinants, and transformations</h3>
      <p>An <strong>eigenvector</strong> of a matrix is a direction that the matrix preserves (up to scaling by an eigenvalue). Eigen-decompositions underlie methods like PCA, frequently used to reduce the dimensionality of imaging data.</p>
      <p>The <strong>determinant</strong> of a transformation measures how volumes change under that mapping. In registration and morphometry, Jacobian determinants quantify local expansion or compression between brain images.</p>

      <p class="marginnote"><strong>Critical perspective – Tensors in diffusion MRI:</strong> Tensors are not just bigger matrices. In diffusion MRI, tensor models encode directional dependence of water diffusion. Assumptions of symmetry, positive-definiteness, and noise properties can strongly influence downstream measures (e.g., FA, MD). Mis-specified tensor models may produce visually plausible but misleading maps.</p>
    </section>

    <!-- Fourier transforms -->
    <section id="fourier">
      <h2>Fourier Transforms</h2>
      <p><span class="newthought">The Fourier transform</span> decomposes a signal into a mixture of sinusoids at different frequencies. Instead of focusing only on how a signal changes over time or space, we ask which frequencies are present and how strong they are.</p>

      <p><span class="badge">MRI reconstruction</span> <span class="badge">Artifact characterization</span> <span class="badge">Signal processing</span></p>

      <h3>Continuous-time Fourier transform</h3>
      <p>For a continuous-time signal <span class="inline-math">\(x(t)\)</span>, the Fourier transform <span class="inline-math">\(X(f)\)</span> is</p>
      <p style="text-align:center;">
        <span class="inline-math">\( X(f) = \int_{-\infty}^{\infty} x(t)\, e^{-j 2\pi f t}\, dt \)</span>
      </p>
      <p>where <span class="inline-math">\(j = \sqrt{-1}\)</span>, <span class="inline-math">\(t\)</span> is time, and <span class="inline-math">\(f\)</span> is frequency. Each frequency has a complex coefficient encoding amplitude and phase.</p>

      <h3>Discrete-time Fourier transform (DFT)</h3>
      <p>Real experimental data are sampled at a finite set of time points <span class="inline-math">\(n = 0, \dots, N-1\)</span>. A discrete Fourier transform can be written:</p>
      <p style="text-align:center;">
        <span class="inline-math">\( X[k] = \sum_{n=0}^{N-1} x[n]\, e^{-j2\pi kn/N}, \quad k = 0,\dots,N-1. \)</span>
      </p>
      <p>Efficient FFT algorithms compute this and are core to MRI reconstruction and spectral analyses in EEG/MEG.</p>

      <figure>
        <img src="fourier_pairs.png" alt="Common waveforms and their Fourier transforms" />
        <figcaption><strong>Figure 7.</strong> Examples from Lecture 1: a cosine, sinc, Gaussian, and double exponential with corresponding Fourier magnitude spectra. These illustrate how time-domain shape determines spectral spread.</figcaption>
      </figure>

      <h3>From simple waves to square waves</h3>
      <p>Lecture 1 shows how a square wave can be approximated using only sine waves at odd harmonics. Adding more terms sharpens the edges but also introduces oscillations near discontinuities (Gibbs phenomenon).</p>

      <figure>
        <img src="square_wave_terms.png" alt="Square wave approximation with increasing terms" />
        <figcaption><strong>Figure 8.</strong> Square wave approximations with 1, 3, 5, 10, and 50 terms. As more harmonics are added, the approximation becomes sharper but overshoots near edges—a key intuition for understanding ringing artifacts in imaging.</figcaption>
      </figure>

      <pre># Pseudocode for constructing a square wave from odd harmonics
A = 1          # amplitude
T = 2 * π      # period
t = linspace(0, 4 * π, 1000)

def square_wave(t, T, A, n_terms):
    y = zeros_like(t)
    for n in range(1, n_terms + 1, 2):  # odd harmonics
        y += (4 * A / (π * n)) * sin(2 * π * n * t / T)
    return y</pre>

      <p class="marginnote"><strong>Limitation – Ideal assumptions vs real scanners:</strong> Fourier methods assume linearity, stationarity, and sufficient sampling. In MRI, motion, gradient imperfections, and time constraints all violate these assumptions to varying degrees, producing aliasing, ghosting, and blurring if not addressed.</p>

      <h3>Fourier space (k-space) in MRI</h3>
      <figure>
        <img src="kspace_patterns.png" alt="k-space points and corresponding sinusoidal patterns" />
        <figcaption><strong>Figure 9.</strong> Illustration of how individual points in k-space correspond to sinusoidal spatial patterns in the image domain.</figcaption>
      </figure>
      <p>MRI scanners acquire data directly in k-space. The final image is obtained by an inverse Fourier transform that converts this frequency representation into a spatial map of voxel intensities.</p>

      <h3>Water–fat phase example</h3>
      <figure>
        <img src="water_fat_phase.png" alt="Water and fat signal phase interaction with MRI images" />
        <figcaption><strong>Figure 10.</strong> Example of water and fat signals being out of phase (left) and in phase (right). Phase relationships in the frequency domain can dramatically alter the appearance of voxels in the reconstructed image.</figcaption>
      </figure>

      <h3>Interactive demos</h3>
      <p>These demos help build intuition about how time/space changes relate to changes in the Fourier spectrum:</p>
      <ul>
        <li><a href="https://www.compadre.org/osp/pwa/soundanalyzer/" target="_blank">Microphone Sound Analyzer – live audio spectrum</a></li>
        <li><a href="https://audiomotion.app/" target="_blank">audioMotion Analyzer – real-time audio spectrum visualizer</a></li>
        <li><a href="https://mriquestions.com/fourier-transform-ft.html" target="_blank">MRIQuestions – Fourier Transform in MRI</a></li>
      </ul>

      <p class="marginnote"><strong>Critical perspective – Convolution and image quality:</strong> Blurring an image with a point spread function is equivalent to multiplying its Fourier transform by a smoothing kernel. Imperfect gradients, motion, and reconstruction choices effectively convolve anatomy with non-ideal kernels. Some apparent "activations" or subtle structural findings may partly reflect these imaging-system properties.</p>
    </section>

    <!-- Integration -->
    <section id="integration">
      <h2>How These Tools Work Together in Neuroimaging</h2>
      <p><span class="newthought">In practice</span>, pixels/voxels, linear algebra, and Fourier transforms form a tightly linked pipeline:</p>
      <ol>
        <li><strong>Acquisition in k-space</strong> — the scanner samples a signal that is naturally expressed in a Fourier basis.</li>
        <li><strong>Reconstruction via FFT</strong> — inverse Fourier transforms map k-space data to a voxelized representation of the brain.</li>
        <li><strong>Representation as matrices and tensors</strong> — multi-voxel, multi-time, multi-subject datasets are arranged into matrices or higher-order tensors.</li>
        <li><strong>Linear modeling and decomposition</strong> — GLM, PCA, ICA, and related tools use matrix and tensor operations to extract patterns.</li>
        <li><strong>Interpretation in anatomical space</strong> — results are mapped back onto voxel grids and anatomical images for visualization and inference.</li>
      </ol>
      <p class="marginnote"><strong>Take-home message:</strong> Without these mathematical foundations, modern neuroimaging would not exist. Mastery of Lecture 1 content is essential for critically evaluating acquisition settings, pipelines, and scientific claims throughout the course.</p>
    </section>

    <!-- Critical Evaluation -->
    <section id="critical-evaluation">
      <h2>Critical Evaluation: Limitations, Advances, and Debates</h2>

      <h3>Limitations of classical Fourier-based approaches</h3>
      <ul>
        <li><strong>Sampling limits and aliasing</strong> — Nyquist sampling assumptions are often strained by scan time and patient comfort. Under-sampling in k-space leads to aliasing and structured artifacts if reconstruction is not adapted.</li>
        <li><strong>Stationarity assumptions</strong> — Many Fourier analyses assume signals are stationary over the analysis window. Task-related transients, drifts, and physiological fluctuations can violate this.</li>
        <li><strong>Noise and model mismatch</strong> — Real scanners are not perfectly linear, shift-invariant systems. Gradient nonlinearity, RF inhomogeneity, and physiological noise distort both time/space and frequency representations.</li>
      </ul>

      <p class="marginnote"><strong>Interpretation implication:</strong> When reading a methods section that simply says "standard Fourier reconstruction" or "k-space was reconstructed with an FFT," it is important to ask which assumptions were made, whether they were violated, and how that might bias results.</p>

      <h3>Recent advances built on these foundations</h3>
      <ul>
        <li><strong>Parallel imaging (SENSE, GRAPPA)</strong> — Uses multiple receive coils to reconstruct images from under-sampled k-space, effectively trading spatial encoding burden between hardware and sampling density.</li>
        <li><strong>Compressed sensing</strong> — Exploits sparsity of images in transform domains (e.g., wavelets) to reconstruct high-quality images from dramatically fewer samples than classical Fourier theory would suggest are necessary.</li>
        <li><strong>Model-based and deep-learning reconstructions</strong> — Combine physical encoding models with learned priors to improve image quality and reduce artifacts, moving beyond purely linear transforms.</li>
      </ul>

      <p class="marginnote"><strong>Connection back to Lecture 1:</strong> All of these methods still use Fourier encoding, matrices, and tensors, but they explicitly capitalize on additional structure—coil sensitivities, sparsity, learned image manifolds—to bypass some limitations of classical Fourier reconstruction.</p>

      <h3>Ongoing debates</h3>
      <ul>
        <li><strong>How much acceleration is safe?</strong> — Aggressive k-space under-sampling can introduce subtle, spatially structured artifacts that may mimic or obscure true neural effects.</li>
        <li><strong>Time/space vs frequency-domain processing</strong> — Some pipelines prioritize Fourier-domain filtering; others rely on time-domain or spatial-domain approaches for motion and physiological correction.</li>
        <li><strong>Interpretation of high-dimensional decompositions</strong> — PCA/ICA-derived "networks" or tensor components are mathematically well-defined but sometimes biologically ambiguous.</li>
      </ul>
    </section>

    <!-- Pitfalls -->
    <section id="pitfalls">
      <h2>Common Pitfalls and Frequently Asked Questions</h2>

      <h3>"Is a voxel just a smaller pixel?"</h3>
      <p>Not exactly. A voxel is a 3D volume; it aggregates signal over a finite cube of tissue. Partial volume effects (multiple tissue types in one voxel) can confound interpretation.</p>

      <h3>"Why do we need tensors instead of matrices?"</h3>
      <p>Matrices can only encode two axes at once. Imaging experiments often track space, time, condition, and subject simultaneously. Tensors preserve this multi-axis structure instead of flattening it, which aids interpretation and modeling.</p>

      <h3>"Fourier transforms feel abstract. How is this MRI?"</h3>
      <p>In MRI, the scanner acquires Fourier coefficients (k-space) by varying gradient fields. Images are recovered via an inverse Fourier transform. Without Fourier theory, standard MRI reconstruction would not work.</p>

      <h3>"Why do sharp edges cause ringing artifacts?"</h3>
      <p>Ideal square waves require infinitely many high-frequency components. Truncating the series produces oscillations near edges (Gibbs ringing). Similar behavior occurs near tissue boundaries in MR images, where acquisition bandwidth and reconstruction choices limit the highest frequencies.</p>
    </section>

    <!-- Summary -->
    <section id="summary">
      <h2>Summary and Self-Check</h2>
      <p><span class="newthought">Before moving on</span>, make sure you can:</p>
      <ul>
        <li>Explain the difference between pixels and voxels and why voxel size matters.</li>
        <li>Give an example of scalar, vector, matrix, and tensor representations in neuroimaging.</li>
        <li>State the continuous and discrete Fourier transform equations and describe them intuitively.</li>
        <li>Describe at least two limitations of classical Fourier-based imaging methods.</li>
        <li>Summarize one recent methodological advance (e.g., parallel imaging, compressed sensing) and how it builds on these foundations.</li>
      </ul>
    </section>

    <!-- References -->
    <section id="references">
      <h2>References</h2>

      <h3>Primary source</h3>
      <ul>
        <li>Bolding, M. (2025). <em>NBL 625/425 – Methods in Human Neuroimaging, Lecture 1: Mathematical foundations of imaging</em>. University of Alabama at Birmingham.</li>
        <li>Gonzalez, R. C., & Woods, R. E. (2018). <em>Digital Image Processing</em> (4th ed.). Pearson.</li>
        <li>McRobbie, D. W., Moore, E. A., Graves, M. J., & Prince, M. R. (2017). <em>MRI from Picture to Proton</em> (3rd ed.). Cambridge University Press.</li>
        <li>Strang, G. (2016). <em>Introduction to Linear Algebra</em> (5th ed.). Wellesley-Cambridge Press.</li>
        <li>Poldrack, R. A., Mumford, J. A., & Nichols, T. E. (2011). <em>Handbook of Functional MRI Data Analysis</em>. Cambridge University Press.</li>
        <li>Bracewell, R. N. (2000). <em>The Fourier Transform and Its Applications</em> (3rd ed.). McGraw–Hill.</li>
        <li>MRIQuestions.com. (n.d.). <em>Fourier Transform (FT) in MRI</em>. https://mriquestions.com/fourier-transform-ft.html</li>
        <li>Brown, R. W., Cheng, Y. C. N., Haacke, E. M., Thompson, M. R., & Venkatesan, R. (2014). <em>Magnetic Resonance Imaging: Physical Principles and Sequence Design</em> (2nd ed.). Wiley.</li>
        <li>Lustig, M., Donoho, D., & Pauly, J. M. (2007). Sparse MRI. <em>Magnetic Resonance in Medicine</em>, 58(6), 1182–1195.</li>
      </ul>

      <h3>Web demos and explanatory resources</h3>
      <ul>
        <li>Compadre OSP. (n.d.). <em>Microphone Sound Analyzer</em> [Interactive simulation]. <a href="https://www.compadre.org/osp/pwa/soundanalyzer/" target="_blank">https://www.compadre.org/osp/pwa/soundanalyzer/</a></li>
        <li>Vianna, H. (n.d.). <em>audioMotion Analyzer</em> [Web application]. <a href="https://audiomotion.app/" target="_blank">https://audiomotion.app/</a></li>
        <li><em>Fourier Transform (FT)</em>. (n.d.). MRIQuestions.com. <a href="https://mriquestions.com/fourier-transform-ft.html" target="_blank">https://mriquestions.com/fourier-transform-ft.html</a></li>
      </ul>

      <h3>Additional figures / methodological advances</h3>
      <ul>
        <li>Bolding, M. (2025); ChatGPT, OPENAI (2025)</li>
      </ul>
    </section>

    <footer style="margin-top: 4rem; padding-top: 2rem; border-top: 1px solid #ccc; font-size: 1.1rem; color: #555;">
      <p>This page is a Tufte-style redesign of Lecture 1 for NBL 625/425. Save as <code>index.html</code> in a GitHub Pages repository or view locally in a browser. You may also export it as a PDF (Print → Save as PDF) if a static copy is required for submission.</p>
    </footer>
  </article>
</body>
</html>
